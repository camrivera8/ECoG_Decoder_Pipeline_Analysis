# -*- coding: utf-8 -*-
"""decoder_lineardiscriminantanalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zr3h2zLlxgDp_g5OYqdTw34ZgW-CDMKc

# Bimanual Discrimination

##Load Packages
"""

#%% PIP installs
!pip install mne
!pip install pycaret
!pip install "scikit-learn==1.3"
!pip install bids
#!pip install git+https://github.com/umnil/preprocessing-pipeline.git#egg=preprocessing_pipeline
!pip install ipympl

#%% Import Packages
# Imports
import os
import mne
import json
import time

import pycaret
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import pickle


# Analysis
import numpy as np
from numpy import log10
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from scipy.stats import f_oneway
#from sklearn.utils import resample
from statistics import mean

from bids import BIDSLayout, BIDSLayoutIndexer
from pathlib import Path
import pipeline2
from pipeline2 import funcs
from pipeline2 import TFunctionTransformer, TransformFeatureUnion, TransformPipeline, Windower
from pipeline2.mne import Labeler
from mne.decoding import Vectorizer
from mne.filter import create_filter
from rich.progress import track
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from  sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.preprocessing import FunctionTransformer, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from sklearn import svm
from sklearn import metrics
from sklearn.metrics import auc
from sklearn.metrics import RocCurveDisplay
from sklearn.metrics import roc_curve
from sklearn.metrics import accuracy_score
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import validation_curve
from sklearn.preprocessing import label_binarize

# Paths
exp_dir = Path("C:\\Users\\nac-calderlab\\Documents")
data_dir = exp_dir #/ "data"
bimanual_dir = data_dir #/ "bimanual"
bids_dir = bimanual_dir / "bids-dataset_train_test"
processed_dir = bimanual_dir / "Processed"
cached_dir = bimanual_dir / "Cache"
models_dir = cached_dir / "models"
src_dir = bimanual_dir / "src"
bm_src_dir = exp_dir / "src" / "analysis"
fig_dir = exp_dir / "reports" / "figures"

bids_dir2 = bimanual_dir / "bids-dataset_validation"


# MNE is really verbose. Supress the messages unless they're critical
mne.set_log_level("critical")


#%% Data Loading

# Load the BIDS dataset
bids_indexer = BIDSLayoutIndexer(validate=False)  # This helps loading process faster
bids_layout = BIDSLayout(bids_dir, indexer=bids_indexer)

bids_layout.get_tasks()

# NOTE: only initial training has the "BOTH" marker
training_set_name = "baselinetraining"
testing_set_name = "baselinetesting"
initial_set_name = "initialtraining"

training_files = bids_layout.get(task=training_set_name, extension="edf")
testing_files = bids_layout.get(task=testing_set_name, extension="edf")
initial_files = bids_layout.get(task=initial_set_name, extension="edf")

# Some sessions were bad. filter by the notes using helper functions
get_run_session_id = lambda f: f.get_entities()["session"]
get_ses_notes_file = lambda f: bids_layout.get(session=get_run_session_id(f), suffix="notes")[0].path
get_ses_notes = lambda f: json.load(open(get_ses_notes_file(f)))
get_run_notes = lambda f: get_ses_notes(f)[f"run-{f.get_entities()['run']}"]
is_run_null = lambda f: get_run_notes(f)["null trial"] == True

training_files = [f for f in training_files if is_run_null(f) == False]
testing_files = [f for f in testing_files if is_run_null(f) == False]
initial_files = [f for f in initial_files if is_run_null(f) == False]

# Load raw data
train_raws = [mne.io.read_raw_edf(f.path, preload=True) for f in training_files]
test_raws = [mne.io.read_raw_edf(f.path, preload=True) for f in testing_files]
initial_raws = [mne.io.read_raw_edf(f.path, preload=True) for f in initial_files]

initial_raws1 = initial_raws[:16]
initial_raws2 = initial_raws[16:]
# # Load the data from the RawEDF objects
# for raw in train_raws:
#     raw.load_data()

help(Windower.__init__)

#%% Method 1: Model Pipeline Setup
"""## Model Pipeline

This pipeline is composed of two components a time-based pipeline for timeseries data and a power-based pipeline for power data

the time pipeline extracts the time series data from the input data, windows the data, then filters it, then performs power spectral density estimation to create power featurs for each window

The power pipeline extracts the power channels, windows the data, and uses a median value for each window

The final pipeline then merges the output from theses to pipelines, scales the data, then pushes the data through to linear discriminant analysis

#Set & Run Model
"""

min_per_run = 5

time_pipeline = TransformPipeline([
    ("label", Labeler(labels=["Rest", "Right", "Left", "Both"], channels=[0, 2])),
    ("window", Windower(trial_size=min_per_run*60*200, window_step=80, samples_per_window=8*80, label_scheme=3)),
    ("concat", TFunctionTransformer(funcs.concat, kw_args=dict(active=True, keep_mask=False))),
    ("filtering", mne.decoding.TemporalFilter(sfreq=200, l_freq=1)),
    ("psd", mne.decoding.PSDEstimator(sfreq=200, adaptive=True, low_bias=True)),
    ("vec", Vectorizer())
    #("vec", FunctionTransformer(lambda x: x.reshape(x.shape[0], -1)))
])

power_pipeline = TransformPipeline([
    ("label", Labeler(labels=["Rest", "Right", "Left", "Both"], channels=[1, 3])),
    ("window", Windower(trial_size=min_per_run*60*200, window_step=80, samples_per_window=8*80, label_scheme=3)),
    ("concat", TFunctionTransformer(funcs.concat, kw_args=dict(active=True, keep_mask=False))),
    ("median", FunctionTransformer(lambda x: np.median(x, axis=-1)))
])

final_pipeline_lda = TransformPipeline([
    # ("union", TransformFeatureUnion([
        # ("time", time_pipeline),
        # ("power", power_pipeline)
    # ])),

    ("ss", StandardScaler()),
    ("lda", LinearDiscriminantAnalysis())
])

final_pipeline_ml_pre = TransformPipeline([
    # ("union", TransformFeatureUnion([
        # ("time", time_pipeline),
        # ("power", power_pipeline)
    # ])),

    ("ss", StandardScaler()),
])


#%% Train + Fit + Test Model
"""###Train/Fit Model + Test Model

Fit the model with train data
"""

# Process the data
# x will be a MxN matrix M = Windows, N = the 2 linear disciminants
# y = will be the labels of each window based on the labeling scheme

# note that the transform function takes and x and y value, We give an
# empty y value because it will be overwritten during the windowing
# process
#train1 = train_raws
train1 = initial_raws1


xt_time = time_pipeline.fit_transform(train1, np.empty(0))
yt_time = time_pipeline._y_hat
xt_power = power_pipeline.fit_transform(train1, np.empty(0))
yt_power = power_pipeline._y_hat

x_lda = final_pipeline_lda.fit_transform(np.c_[xt_time, xt_power], yt_time)
y_lda = final_pipeline_lda._y_hat

x_ml = final_pipeline_ml_pre.fit_transform(np.c_[xt_time, xt_power], yt_time)
y_ml = final_pipeline_ml_pre._y_hat

#x2, y2 = power_pipeline.transform(train_raws, np.empty(0))
#x3, y3 = pipeline.transform(train_raws, np.empty(0))

"""Run the test data transformer

"Setup" dictates the testing data (test_raws or initial_raws)
"""

#setup = "test"
#setup = "initial"
setup = "initial2"


if setup == "test":
  test_set = test_raws
if setup == "initial":
  test_set = initial_raws
if setup == "initial2":
  test_set = initial_raws2

xt_test_time, yt_test_time = time_pipeline.transform(test_set, np.empty(0))
xt_test_power, yt_test_power = power_pipeline.transform(test_set, np.empty(0))

# run pipeline for LDA outputs
x_lda_test, y_lda_test = final_pipeline_lda.transform(np.c_[xt_test_time, xt_test_power], yt_test_time)

# run pipeline for machine learning (through standard scaler)
x_ml_test, y_ml_test = final_pipeline_ml_pre.transform(np.c_[xt_test_time, xt_test_power], yt_test_time)

#%% Mean PSD Graph

mean_pipeline = TransformPipeline([
    ("label", Labeler(labels=["Rest", "Right", "Left", "Both"], channels=[0, 2])),
    ("window", Windower(trial_size=min_per_run*60*200, window_step=80, samples_per_window=8*80, label_scheme=3)),
    ("concat", TFunctionTransformer(funcs.concat, kw_args=dict(active=True, keep_mask=False))),
    ("filtering", mne.decoding.TemporalFilter(sfreq=200, l_freq=1)),
    ("psd", mne.decoding.PSDEstimator(sfreq=200, adaptive=True, low_bias=True)),
    ("psd_transformer", FunctionTransformer(lambda x: 20*log10(x)))
    #("vec", Vectorizer())
    #("vec", FunctionTransformer(lambda x: x.reshape(x.shape[0], -1)))
])


xt_mean = mean_pipeline.fit_transform(train1, np.empty(0))
yt_mean = mean_pipeline._y_hat


# Define the channel names
channel_names = ["Lead 1", "Lead 2"]

# Iterate over channels
for channel_idx in range(xt_mean.shape[1]):
    # Separate data for the current channel
    channel_data = xt_mean[:, channel_idx, :]
    
    # Initialize dictionary to store PSD for each class
    psd_by_class = {label: [] for label in np.unique(yt_mean)}
    
    # Iterate over data and collect PSD for each class
    for i, label in enumerate(yt_mean):
        psd_by_class[label].append(channel_data[i])
    
    # Plot mean PSD for each class
    plt.figure(figsize=(10, 6))
    for label, psd_list in psd_by_class.items():
        mean_psd = np.mean(psd_list, axis=0)
        std_psd = np.std(psd_list, axis=0)
        freqs = np.linspace(0, 100, len(mean_psd))  # Adjust frequency range accordingly
        plt.plot(freqs, mean_psd, label=label)
        plt.fill_between(freqs, mean_psd - std_psd, mean_psd + std_psd, alpha=0.2)
    
    plt.xlabel('Frequency (Hz)')
    plt.ylabel('Power Spectral Density')
    plt.title(f'Average Power Spectral Density for {channel_names[channel_idx]}')
    plt.legend()
    plt.show()

#%% Train + Fit + Test Model
"""###Train/Fit Model + Test Model

Fit the model with train data
"""

# Process the data
# x will be a MxN matrix M = Windows, N = the 2 linear disciminants
# y = will be the labels of each window based on the labeling scheme

# note that the transform function takes and x and y value, We give an
# empty y value because it will be overwritten during the windowing
# process
train = initial_raws1
test = initial_raws2

xt_time = time_pipeline.fit_transform(train, np.empty(0))
yt_time = time_pipeline._y_hat
xt_power = power_pipeline.fit_transform(train, np.empty(0))
yt_power = power_pipeline._y_hat

x_lda = final_pipeline_lda.fit_transform(np.c_[xt_time, xt_power], yt_time)
y_lda = final_pipeline_lda._y_hat

x_ml = final_pipeline_ml_pre.fit_transform(np.c_[xt_time, xt_power], yt_time)
y_ml = final_pipeline_ml_pre._y_hat

#x2, y2 = power_pipeline.transform(train_raws, np.empty(0))
#x3, y3 = pipeline.transform(train_raws, np.empty(0))

"""Run the test data transformer

"Setup" dictates the testing data (test_raws or initial_raws)
"""

#setup = "test"
#setup = "initial"
setup = "initial2"


if setup == "test":
  test_set = test_raws
if setup == "initial":
  test_set = initial_raws
if setup == "initial2":
  test_set = initial_raws2

xt_test_time, yt_test_time = time_pipeline.transform(test_set, np.empty(0))
xt_test_power, yt_test_power = power_pipeline.transform(test_set, np.empty(0))

# run pipeline for LDA outputs
x_lda_test, y_lda_test = final_pipeline_lda.transform(np.c_[xt_test_time, xt_test_power], yt_test_time)

# run pipeline for machine learning (through standard scaler)
x_ml_test, y_ml_test = final_pipeline_ml_pre.transform(np.c_[xt_test_time, xt_test_power], yt_test_time)

#%% Analyze LDA
"""### Analyze LDA"""

# transformed_data = []
# for raw in train_raws:
#     transformed_data.append(time_pipeline.fit_transform(raw))
#data = pd.DataFrame(np.c_[x, y])

"""#LDA had returned 3 outputs, reduced to 2 for LDA1/LDA2 (assumes that these are first 2 columns)"""
x_lda_test2 = pd.DataFrame(x_lda_test)
x_lda_test2 = x_lda_test2.iloc[:,:2]

# Plot LDA
data = pd.DataFrame(np.c_[x_lda_test2, y_lda_test], columns=["LDA1", "LDA2", "target"])
data.head()

sns.scatterplot(x="LDA1", y="LDA2", hue="target", data=data)



#%% Analyze ML **train/test**
"""### Analyze ML

Prep Data
"""

# dividing X, y into train and test data
#X_train, X_test, y_train, y_test = train_test_split(x_ml_test, y_ml_test, train_size = 0.8, random_state = 210)

"""Random Forest"""

rf = RandomForestClassifier(max_depth=50, min_samples_leaf=2, min_samples_split=10,n_estimators=200, oob_score = True)
# rf = rf.fit(X_train, y_train)
# rf_predictions = rf.predict(X_test)
# rf_predict_proba = rf.predict_proba(X_test)

# accuracy = rf.score(X_test, y_test)
# print(accuracy)

gbc=GradientBoostingClassifier(max_depth=15, max_features=10, min_samples_leaf=2, min_samples_split=10, n_estimators=1100)
# gbc=gbc.fit(X_train, y_train)
# gbc_predictions = gbc.predict(X_test)
# gbc_predict_proba = gbc.predict_proba(X_test)

# accuracy = gbc.score(X_test, y_test)
# print(accuracy)

log_reg = LogisticRegression()
mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', alpha=0.0001, solver='adam', learning_rate='constant')
knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', p=2)
svc = SVC(kernel='rbf', C=1.0, gamma='auto', class_weight=None, probability=False)



#%% 5-Fold Cross-Validation

###############################################
# Choose Model Name below                     #
# Will Apply to the Cross-Validation AUC Code #
###############################################

# Determine which models we are running    
models_to_run = "all"
#models_to_run = "first"
    
models = ('log_reg', 'gbc', 'rf', 'mlp', 'svc', 'knn')
#model_name = "log_reg"
#model_name = "gbc"
#model_name = "rf"
#model_name = "mlp"
#model_name = "svm"
#model_name = "knn"
####################
for model_name in models:
    # Set up timer per model
    model_start_time = time.time()    

    
    # Automate the model/graph/figure to match
    if model_name == "log_reg":
      model = log_reg
      model_name_fig = "logistic_regression"
      model_name_title = "Logistic Regression Classifier"
    if model_name == "gbc":
      model = gbc
      model_name_fig = "gradient_boosting"
      model_name_title = "Gradient Boosting Classifier"
      #Break if only running first model
      if models_to_run == "first":
          break
    if model_name == "rf":
      model = rf
      model_name_fig = "random_forest"
      model_name_title = "Random Forest Classifier"
    if model_name == "mlp":
      model = mlp
      model_name_fig = "multilayer_perceptron"
      model_name_title = "MLP Neural Network Classifier"
    if model_name == "svc":
      model = rf
      model_name_fig = "support_vector_machine"
      model_name_title = "Support Vector Classifier"
    if model_name == "knn":
      model = knn
      model_name_fig = "k_nearest_neighbors"
      model_name_title = "K-Nearest Neighbors Classifier"
    
    
    print("Running: " + model_name_title)
    cv = StratifiedKFold(n_splits=5)
    
    # Rename data to fit code
    X_smote = pd.DataFrame(x_ml_test)
    y_smote = pd.DataFrame(y_ml_test)
    
    # Names of the classes
    class_label = ['Rest', 'Right', 'Left', 'Both']
    
    #Binarize the output
    y_tres_bin = label_binarize(y_smote, classes=[0, 1, 2, 3])
    n_classes = y_tres_bin.shape[1]
    
    fpr = dict()
    tpr = dict()
    metrics_class = dict()
    tprs = []
    aucs = []
    roc_auc = dict()
    mean_fpr = np.linspace(0, 1, 100)
    

    # Loop over all 4 OvR classes
    for i in range(n_classes):
      # Start Class Timer
      class_time_start = time.time()
      #
      # Set Empty Metrics Structs
      precision = []
      specificity = []
      sensitivity = []
      f1 = []
      accuracy = []
      print(f'Class: {i}')
      # Cross-Validation x5 within each class
      for fold, (train, test) in enumerate(cv.split(X_smote, y_smote)):
        model.fit(X_smote.iloc[train], y_smote.iloc[train])
        y_smote_test_bin_pre = label_binarize(y_smote.iloc[test], classes=[0, 1, 2, 3])
        y_smote_test_bin = y_smote_test_bin_pre[:,i]
        #
        y_score = model.predict_proba(X_smote.iloc[test])

        y_score_bin = y_score[:,i]
        y_score_bin = pd.DataFrame(y_score_bin)
        #
        #
        # Calculate AUC Stats
        fpr[fold], tpr[fold], _ = roc_curve(y_smote_test_bin, y_score_bin)
        #plt.plot(fpr[fold], tpr[fold], color='darkorange', lw=2)
        print('AUC for {}: {}'.format(fold+1, auc(fpr[fold], tpr[fold])))
        auc_fold = auc(fpr[fold], tpr[fold])
        #
        interp_tpr = np.interp(mean_fpr, fpr[fold], tpr[fold])
        interp_tpr[0] = 0.0
        tprs.append(interp_tpr)
        aucs.append(auc_fold)
        #
        # Translate predictions & classifier for following code
        y_true = y_smote_test_bin
        y_pred = np.where(y_score_bin > 0.5, 1, 0)
        #
        # Pre-Existing Code for metrics
        precision.append(metrics.precision_recall_fscore_support(y_true, y_pred)[0][1])
        sensitivity.append(metrics.precision_recall_fscore_support(y_true, y_pred)[1][1])
        f1.append(metrics.precision_recall_fscore_support(y_true, y_pred)[2][1])
        accuracy.append(metrics.accuracy_score(y_true, y_pred))
        specificity.append(metrics.precision_recall_fscore_support(y_true, y_pred)[1][0])
        #
        #end 5-fold loop
      #
      # Calculate mean stats for the class i
      mean_accuracy = mean(accuracy)
      mean_precision = mean(precision)
      mean_specificity = mean(specificity)
      mean_sensitivity = mean(sensitivity)
      mean_f1 = mean(f1)
      #
      metrics_class[i] = {"accuracy": accuracy,
                          "precision": precision,
                          "specificity": specificity,
                          "sensitivity": sensitivity,
                          "f1-score": f1}
      #
      #
      # Plot the mean + std AUC for class i
      plt.plot([0, 1], [0, 1], "k--", label="Chance (AUC = 0.5)")
      #
      #
      #
      #
      mean_tpr = np.mean(tprs, axis=0)
      mean_tpr[-1] = 1.0
      mean_auc = auc(mean_fpr, mean_tpr)
      std_auc = np.std(aucs)
      plt.plot(
          mean_fpr,
          mean_tpr,
          color="m",
          label=r"Mean ROC (AUC = %0.2f $\pm$ %0.2f)" % (mean_auc, std_auc),
          lw=2,
          alpha=0.8
      )
      #
      #
      std_tpr = np.std(tprs, axis=0)
      tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
      tprs_lower = np.maximum(mean_tpr - std_tpr, 0)
      plt.fill_between(
          mean_fpr,
          tprs_lower,
          tprs_upper,
          color="grey",
          alpha=0.2,
          label=r"$\pm$ 1 std dev",
      )
      #
      #    
      plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
      plt.xlim([0.0, 1.0])
      plt.ylim([0.0, 1.05])
      plt.xlabel('False Positive Rate')
      plt.ylabel('True Positive Rate')
      plt.title(f'{model_name_title} Multiclass Classification AUC\'s: ' + class_label[i])
      plt.legend(loc=4)
      #
      # Print Mean Metrics
      metrics_auc = [mean_accuracy, mean_precision, mean_specificity, mean_sensitivity, mean_f1]
      print("mean accuracy: " + str(mean_accuracy))
      print("mean precision: " + str(mean_precision))
      print("mean specificity: " + str(mean_precision))
      print("mean sensitivity: " + str(mean_sensitivity))
      print("mean F1-Score: " + str(mean_f1))
      #
      #
      plt.savefig(f'C:\\Users\\nac-calderlab\\Documents\\ECoG_Decoding\\figures\\{model_name_fig}_model_5fold_auc_class{class_label[i]}_test.png')
      plt.show()
      #end OvR loop
      #   
      metrics_class[class_label[i]] = {
          "accuracy": mean_accuracy,
          "precision": mean_precision,
          "specificity": mean_specificity,
          "sensitivity": mean_sensitivity,
          "f1-score": mean_f1}
      #
      # End Loop Time
      class_time_end = time.time()
      total_class_time = class_time_end - class_time_start
      print(f"{class_label[i]} Class Run Time: " + str(total_class_time) + "s")
      #
    with open(f'C:\\Users\\nac-calderlab\\Documents\\ECoG_Decoding\\figures\\{model_name}_metrics_test.pkl', "wb") as f:
        pickle.dump(metrics_class, f)
    #
    #End Model Timer
    model_end_time = time.time()
    total_model_time = model_end_time - model_start_time
    print(f"{model_name_title} Run Time: " + str(total_model_time) + "s")
#end of model loop






metrics_dict = {}
for model in models:
    if model == "log_reg":
        model = "logistic_regression"
    if model == "knn":
        continue
    file_path = f'C:\\Users\\nac-calderlab\\Documents\\ECoG_Decoding\\figures\\{model}_metrics_test.pkl'
    if os.path.exists(file_path):
        with open(file_path, "rb") as f:
            try:
                metrics_dict[f'metrics_class_{model}'] = pickle.load(f)
            except EOFError:
                print(f"Error: EOFError occurred while loading file for model {model}")
    else:
        print(f"Error: File not found for model {model}")

metrics_class_logistic_regression = metrics_dict['metrics_class_logistic_regression']; metrics_class_log_reg = metrics_class_logistic_regression #Lower accuracy than GBC, no other metrics saved
metrics_class_gbc = metrics_dict['metrics_class_gbc'] #Best model
metrics_class_rf = metrics_dict['metrics_class_rf'] #Similar accuracies, lower F1 score than GBC (especially both)
metrics_class_mlp = metrics_dict['metrics_class_mlp'] #Close to GBC, but inferior accuracy/f1
metrics_class_svc = metrics_dict['metrics_class_svc'] #Overall low F1's

#%% Method 2: Mean Amplitude Change
"""##Method 2: Amplitude Filtering

Set up bandpass filtering
- separate out signal by bands
- analyze amplitude changes

Extract bands
- from raw EDF -> ECoG filtered by bands
- dictionary ready for windowing pipeline
"""

# # Pick the data to manipulate
# data_raws = train_raws
# #data_raw = test_raws
# #data_raw = initial_raws

#min_per_run = 5

# frequency_bands = {'delta': [1, 8],
#                    'theta': [8, 12],
#                    'alpha': [12, 18],
#                    'beta_lower': [18, 26],
#                    'beta_upper': [26, 35],
#                    'gamma_lower': [35, 45],
#                    'gamma_middle': [45, 70],
#                    'gamma_upper': [70, 99.9]}

# # Start empty dictionary
# filtered_data_sessions = {}

# # Create a dictionary to store filtered data for each frequency band
# filtered_data = {}

# for raw_edf in data_raws:
#     # Get the data and sampling frequency
#     data = raw_edf.get_data()
#     sfreq = raw_edf.info['sfreq']

#     # Dictionary to store filtered data for each frequency band for this session
#     filtered_data = {}

#     # Apply filters for each frequency band
#     for band, (fmin, fmax) in frequency_bands.items():
#         # Design the filter
#         filter_coefs = create_filter(data, sfreq=sfreq, l_freq=fmin, h_freq=fmax, fir_design='firwin')

#         # Apply the filter
#         filtered_data[band] = mne.filter.filter_data(data, sfreq=sfreq, l_freq=fmin, h_freq=fmax, picks=None, filter_length='auto', l_trans_bandwidth='auto', h_trans_bandwidth='auto', n_jobs=1, method='fft', iir_params=None, phase='zero', fir_window='hamming', pad='reflect_limited', verbose=None)

#     # Store filtered data for this session
#     filtered_data_sessions[raw_edf.filenames[0]] = filtered_data

# xt_time = []

# # Iterate over each session's filtered data
# for session_data in filtered_data_sessions.values():
#     # Iterate over each band's data in the session
#     for band_data in session_data.values():
#         # Apply the pipeline to the band's data
#         xt_band = time_pipeline.fit_transform(band_data, np.empty(0))
#         # Append the processed data to the list
#         xt_time.append(xt_band)

# # Concatenate the processed data from all bands and sessions
# xt_time = np.concatenate(xt_time, axis=0)

# add = lambda a, b: a + b

# add(2, 3)


frequency_bands = {'delta': [1, 8],
                   'theta': [8, 12],
                   'alpha': [12, 18],
                   'beta_lower': [18, 26],
                   'beta_upper': [26, 35],
                   'gamma_lower': [35, 45],
                   'gamma_middle': [45, 70],
                   'gamma_upper': [70, 99.9]}

filter_length = 89
min_per_run = 5

time_pipeline_delta = TransformPipeline([
    ("label", Labeler(labels=["Rest", "Right", "Left", "Both"], channels=[0, 2])),
    ("window", Windower(trial_size=min_per_run*60*200, window_step=80, samples_per_window=8*80, label_scheme=3)),
    ("concat", TFunctionTransformer(funcs.concat, kw_args=dict(active=True, keep_mask=False))),
    ("filtering", mne.decoding.TemporalFilter(sfreq=200, l_freq=frequency_bands['delta'][0], h_freq=frequency_bands['delta'][1])),
    #("avg", FunctionTransformer(lambda x: np.abs(x).mean(axis=-1)))
    #("flt", FunctionTransformer(lambda x: x.rehsape(x.shape[0], -1)))
    ])

time_pipeline_theta = TransformPipeline([
    ("label", Labeler(labels=["Rest", "Right", "Left", "Both"], channels=[0, 2])),
    ("window", Windower(trial_size=min_per_run*60*200, window_step=80, samples_per_window=8*80, label_scheme=3)),
    ("concat", TFunctionTransformer(funcs.concat, kw_args=dict(active=True, keep_mask=False))),
    ("filtering", mne.decoding.TemporalFilter(sfreq=200, l_freq=frequency_bands['theta'][0], h_freq=frequency_bands['theta'][1]))
])


time_pipeline_alpha = TransformPipeline([
    ("label", Labeler(labels=["Rest", "Right", "Left", "Both"], channels=[0, 2])),
    ("window", Windower(trial_size=min_per_run*60*200, window_step=80, samples_per_window=8*80, label_scheme=3)),
    ("concat", TFunctionTransformer(funcs.concat, kw_args=dict(active=True, keep_mask=False))),
    ("filtering", mne.decoding.TemporalFilter(sfreq=200, l_freq=frequency_bands['alpha'][0], h_freq=frequency_bands['alpha'][1]))
])

time_pipeline_beta_lower = TransformPipeline([
    ("label", Labeler(labels=["Rest", "Right", "Left", "Both"], channels=[0, 2])),
    ("window", Windower(trial_size=min_per_run*60*200, window_step=80, samples_per_window=8*80, label_scheme=3)),
    ("concat", TFunctionTransformer(funcs.concat, kw_args=dict(active=True, keep_mask=False))),
    ("filtering", mne.decoding.TemporalFilter(sfreq=200, l_freq=frequency_bands['beta_lower'][0], h_freq=frequency_bands['beta_lower'][1]))
])

time_pipeline_beta_upper = TransformPipeline([
    ("label", Labeler(labels=["Rest", "Right", "Left", "Both"], channels=[0, 2])),
    ("window", Windower(trial_size=min_per_run*60*200, window_step=80, samples_per_window=8*80, label_scheme=3)),
    ("concat", TFunctionTransformer(funcs.concat, kw_args=dict(active=True, keep_mask=False))),
    ("filtering", mne.decoding.TemporalFilter(sfreq=200, l_freq=frequency_bands['beta_upper'][0], h_freq=frequency_bands['beta_upper'][1]))
])

time_pipeline_gamma_lower = TransformPipeline([
    ("label", Labeler(labels=["Rest", "Right", "Left", "Both"], channels=[0, 2])),
    ("window", Windower(trial_size=min_per_run*60*200, window_step=80, samples_per_window=8*80, label_scheme=3)),
    ("concat", TFunctionTransformer(funcs.concat, kw_args=dict(active=True, keep_mask=False))),
    ("filtering", mne.decoding.TemporalFilter(sfreq=200, l_freq=frequency_bands['gamma_lower'][0], h_freq=frequency_bands['gamma_lower'][1]))
])

time_pipeline_gamma_middle = TransformPipeline([
    ("label", Labeler(labels=["Rest", "Right", "Left", "Both"], channels=[0, 2])),
    ("window", Windower(trial_size=min_per_run*60*200, window_step=80, samples_per_window=8*80, label_scheme=3)),
    ("concat", TFunctionTransformer(funcs.concat, kw_args=dict(active=True, keep_mask=False))),
    ("filtering", mne.decoding.TemporalFilter(sfreq=200, l_freq=frequency_bands['gamma_middle'][0], h_freq=frequency_bands['gamma_middle'][1])),
])
time_pipeline_gamma_upper = TransformPipeline([
    ("label", Labeler(labels=["Rest", "Right", "Left", "Both"], channels=[0, 2])),
    ("window", Windower(trial_size=min_per_run*60*200, window_step=80, samples_per_window=8*80, label_scheme=3)),
    ("concat", TFunctionTransformer(funcs.concat, kw_args=dict(active=True, keep_mask=False))),
    ("filtering", mne.decoding.TemporalFilter(sfreq=200, l_freq=frequency_bands['gamma_upper'][0], h_freq=frequency_bands['gamma_lower'][1], filter_length=filter_length))
])

#%% Run Time Pipe (can skip, load pickle into next)
"""Run Time Pipe for all bands individually"""
#
# Run the data through each band filter for a unique output in the xt_bands{} dictionary
xt_bands_train = {}
train_time_start = time.time()
for band in frequency_bands.keys():
    xt_bands_train[band] = globals()[f"xt_band_{band}"] = globals()[f"time_pipeline_{band}"].fit_transform(initial_raws1)
train_time_end = time.time()
train_time = train_time_end - train_time_start

with open('xt_bands_train.pickle', 'wb') as f:
    pickle.dump(xt_bands_train, f)



xt_bands_test = {}
test_time_start = time.time()
for band in frequency_bands.keys():
    xt_bands_test[band], yt_bands_test = globals()[f"xt_band_{band}"] = globals()[f"time_pipeline_{band}"].transform(initial_raws2, np.empty(0))
    break
test_time_end = time.time()
test_time = test_time_end - test_time_start

with open('xt_bands_test.pickle', 'wb') as f:
    pickle.dump(xt_bands_test, f)

with open('yt_bands_test.pickle', 'wb') as f:
    pickle.dump(yt_bands_test, f)

#%% Calculate Mean Amplitude
"""Calculate Mean Amplitude"""


with open('xt_bands_test.pickle', 'rb') as f:
    xt_bands_test = pickle.load(f)
with open('yt_bands_test.pickle', 'rb') as f:
    yt_bands_test = pickle.load(f)
    
    
#
mean_bands = {}
#
# Iterate over each band in xt_bands_test
for band, data in xt_bands_test.items():

    # Calculate the mean along the time axis
    mean_bands[band] = np.abs(data).mean(axis=1)
num_entries = len(data)
#
# Make the dictionary of means a dataframe
means_df = pd.DataFrame(columns=['delta', 'theta', 'alpha', 'beta_lower', 'beta_upper', 'gamma_lower', 'gamma_middle', 'gamma_upper'], index=range(num_entries))
#
# Print or use the mean_bands dictionary as needed
# Output = table of 8 bands, rows = entries. Each value is the mean amp per 
for i, (band, mean_data) in enumerate(mean_bands.items()):
  #print(f"Mean for {band}: {mean_data}")
  print("i =", i)
  print("length of data =", len(mean_data))
  means_df[band] = mean_bands[band]
#
# Reset Index on means_df
means_df.reset_index(drop=True, inplace=True)
#
# Convert Classifiers to a Data Frame
means_df_class = pd.DataFrame(yt_bands_test)



data_to_pickle = {
    "means_df": means_df,
    "means_df_class": means_df_class
}

# Save to pickle file
with open("data.pickle", "wb") as f:
    pickle.dump(data_to_pickle, f)

#
#%% Standard Scaler
#
from sklearn.preprocessing import StandardScaler
# Standard Scaler
scaler = StandardScaler()
#
means_df_ss = means_df.copy(deep=True)
#
for col in means_df.columns:
    print(f"Processing column: {col}")
    try:
        means_df_ss[[col]] = scaler.fit_transform(means_df[[col]])
    except Exception as e:
        print(f"Error processing column {col}: {str(e)}")
#
# Store standard scaled data as a picle file
with open("data_ss.pickle", "wb") as f:
    pickle.dump(means_df_ss, f)
#
#
#%% LDA
"""LDA"""
# Load mean amplitude data + classes from pickle
with open("data.pickle", "rb") as f:
    loaded_data = pickle.load(f)
#
# Access "means_df" + "means_df_class" variables from the loaded dictionary
means_df = loaded_data["means_df"]
means_df_class = loaded_data["means_df_class"]
#
# Load mean amplitude standard scaled inputs from pickle
with open("data_ss.pickle", "rb") as f:
    means_df_ss = pickle.load(f)
#
#
#    
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(means_df_ss, means_df_class, test_size=0.9, random_state=42)
#
#
# Linear Discriminant Analysis (LDA)
lda = LinearDiscriminantAnalysis()
lda.fit(X_train, y_train)
x_lda_transform = lda.transform(X_test)
x_lda_transform = pd.DataFrame(x_lda_transform)
x_lda_transform2 = x_lda_transform.iloc[:,:2]
y_pred_lda = lda.predict(X_test)
accuracy_lda = accuracy_score(y_test, y_pred_lda)
print("Accuracy of LDA:", accuracy_lda)
#
data = pd.DataFrame(np.c_[x_lda_transform2, y_test], columns=["LDA1", "LDA2", "target"])
data.head()
#
# Commented out IPython magic to ensure Python compatibility.
# %matplotlib widget
sns.scatterplot(x="LDA1", y="LDA2", hue="target", data=data)
plt.gcf()


#%% Analyze ML
"""### Analyze ML

Prep Data
"""

# dividing X, y into train and test data
#X_train, X_test, y_train, y_test = train_test_split(x_ml_test, y_ml_test, train_size = 0.8, random_state = 210)

"""Random Forest"""

rf = RandomForestClassifier(max_depth=50, min_samples_leaf=2, min_samples_split=10,n_estimators=200, oob_score = True)
# rf = rf.fit(X_train, y_train)
# rf_predictions = rf.predict(X_test)
# rf_predict_proba = rf.predict_proba(X_test)

# accuracy = rf.score(X_test, y_test)
# print(accuracy)

gbc=GradientBoostingClassifier(max_depth=15, max_features=10, min_samples_leaf=2, min_samples_split=10, n_estimators=1100)
# gbc=gbc.fit(X_train, y_train)
# gbc_predictions = gbc.predict(X_test)
# gbc_predict_proba = gbc.predict_proba(X_test)

# accuracy = gbc.score(X_test, y_test)
# print(accuracy)

log_reg = LogisticRegression()
mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', alpha=0.0001, solver='adam', learning_rate='constant')
knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', p=2)
svc = SVC(kernel='rbf', C=1.0, gamma='auto', class_weight=None, probability=False)

#%% 5-Fold Cross-Validation


with open('variables_method2.pickle', 'rb') as f:
    data = pickle.load(f)

# Retrieve variables from the loaded data
mean_df_ss = data['var1']
mean_df_class = data['var2']

# Determine which models we are running    
models_to_run = "all"
#models_to_run = "first"
    
models = ('log_reg', 'gbc', 'rf', 'mlp', 'svc', 'knn')
#model_name = "log_reg"
#model_name = "gbc"
#model_name = "rf"
#model_name = "mlp"
#model_name = "svm"
#model_name = "knn"
####################
for model_name in models:
    # Set up timer per model
    model_start_time = time.time()    

    
    # Automate the model/graph/figure to match
    if model_name == "log_reg":
      model = log_reg
      model_name_fig = "logistic_regression"
      model_name_title = "Logistic Regression Classifier"
    if model_name == "gbc":
      model = gbc
      model_name_fig = "gradient_boosting"
      model_name_title = "Gradient Boosting Classifier"
      #Break if only running first model
      if models_to_run == "first":
          break
    if model_name == "rf":
      model = rf
      model_name_fig = "random_forest"
      model_name_title = "Random Forest Classifier"
    if model_name == "mlp":
      model = mlp
      model_name_fig = "multilayer_perceptron"
      model_name_title = "MLP Neural Network Classifier"
    if model_name == "svc":
      model = rf
      model_name_fig = "support_vector_machine"
      model_name_title = "Support Vector Classifier"
    if model_name == "knn":
      model = knn
      model_name_fig = "k_nearest_neighbors"
      model_name_title = "K-Nearest Neighbors Classifier"
    
    
    print("Running: " + model_name_title)

    cv = StratifiedKFold(n_splits=5)
    
    
    
    
    '''
    Below are the variables that will train the ML models
    The X features are the mean amplitudes per run after a standard scaler
    The y features are 0, 1, 2, 3 representing each class
    '''
    # Rename data to fit code
    X_smote = pd.DataFrame(means_df_ss)
    y_smote = pd.DataFrame(means_df_class)
    '''
    '''
    
    
    
    
    
    # Names of the classes
    class_label = ['Rest', 'Right', 'Left', 'Both']
    
    #Binarize the output
    y_tres_bin = label_binarize(y_smote, classes=[0, 1, 2, 3])
    n_classes = y_tres_bin.shape[1]
    
    fpr = dict()
    tpr = dict()
    metrics_class = dict()
    tprs = []
    aucs = []
    roc_auc = dict()
    mean_fpr = np.linspace(0, 1, 100)
    
    
    # Loop over all 4 OvR classes
    for i in range(n_classes):
      class_time_start = time.time()  
      # Set Empty Metrics Structs
      precision = []
      specificity = []
      sensitivity = []
      f1 = []
      accuracy = []
    
      # Cross-Validation x5 within each class
      for fold, (train, test) in enumerate(cv.split(X_smote, y_smote)):
        model.fit(X_smote.iloc[train], y_smote.iloc[train])
        y_smote_test_bin_pre = label_binarize(y_smote.iloc[test], classes=[0, 1, 2, 3])
        y_smote_test_bin = y_smote_test_bin_pre[:,i]
    
        y_score = model.predict_proba(X_smote.iloc[test])
        y_score_bin = y_score[:,i]
        y_score_bin = pd.DataFrame(y_score_bin)
    
    
        # Calculate AUC Stats
        fpr[fold], tpr[fold], _ = roc_curve(y_smote_test_bin, y_score_bin)
        #plt.plot(fpr[fold], tpr[fold], color='darkorange', lw=2)
        print('AUC for Class {}: {}'.format(fold+1, auc(fpr[fold], tpr[fold])))
        auc_fold = auc(fpr[fold], tpr[fold])
    
        interp_tpr = np.interp(mean_fpr, fpr[fold], tpr[fold])
        interp_tpr[0] = 0.0
        tprs.append(interp_tpr)
        aucs.append(auc_fold)
    
        # Translate predictions & classifier for following code
        y_true = y_smote_test_bin
        y_pred = np.where(y_score_bin > 0.5, 1, 0)
    
        # Pre-Existing Code for metrics
        precision.append(metrics.precision_recall_fscore_support(y_true, y_pred)[0][1])
        sensitivity.append(metrics.precision_recall_fscore_support(y_true, y_pred)[1][1])
        f1.append(metrics.precision_recall_fscore_support(y_true, y_pred)[2][1])
        accuracy.append(metrics.accuracy_score(y_true, y_pred))
        specificity.append(metrics.precision_recall_fscore_support(y_true, y_pred)[1][0])
    
        #end 5-fold loop
    
      # Calculate mean stats for the class i
      mean_accuracy = mean(accuracy)
      mean_precision = mean(precision)
      mean_specificity = mean(specificity)
      mean_sensitivity = mean(sensitivity)
      mean_f1 = mean(f1)
    
      metrics_class[i] = {"accuracy": accuracy,
                          "precision": precision,
                          "specificity": specificity,
                          "sensitivity": sensitivity,
                          "f1-score": f1}
    
    
      # Plot the mean + std AUC for class i
      plt.plot([0, 1], [0, 1], "k--", label="Chance (AUC = 0.5)")
    
    
      mean_tpr = np.mean(tprs, axis=0)
      mean_tpr[-1] = 1.0
      mean_auc = auc(mean_fpr, mean_tpr)
      std_auc = np.std(aucs)
      plt.plot(
          mean_fpr,
          mean_tpr,
          color="m",
          label=r"Mean ROC (AUC = %0.2f $\pm$ %0.2f)" % (mean_auc, std_auc),
          lw=2,
          alpha=0.8
      )
    
      std_tpr = np.std(tprs, axis=0)
      tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
      tprs_lower = np.maximum(mean_tpr - std_tpr, 0)
      plt.fill_between(
          mean_fpr,
          tprs_lower,
          tprs_upper,
          color="grey",
          alpha=0.2,
          label=r"$\pm$ 1 std dev",
      )
    
    
      plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
      plt.xlim([0.0, 1.0])
      plt.ylim([0.0, 1.05])
      plt.xlabel('False Positive Rate')
      plt.ylabel('True Positive Rate')
      plt.title(f'{model_name_title} Multiclass Classification AUC\'s: ' + class_label[i])
      plt.legend(loc=4)
    
      # Print Mean Metrics
           
      metrics_auc = [mean_accuracy, mean_precision, mean_specificity, mean_sensitivity, mean_f1]
      print("mean accuracy: " + str(mean_accuracy))
      print("mean precision: " + str(mean_precision))
      print("mean specificity: " + str(mean_precision))
      print("mean sensitivity: " + str(mean_sensitivity))
      print("mean F1-Score: " + str(mean_f1))
      #
      #
      print(class_label[i])
      plt.savefig(f'C:\\Users\\nac-calderlab\\Documents\\ECoG_Decoding\\figures\\mean_amplitude_{model_name_fig}_model_5fold_auc_class_{class_label[i]}_test.png')
      plt.show()
      #end OvR loop
      #   
      metrics_class[class_label[i]] = {
          "accuracy": accuracy,
          "precision": precision,
          "specificity": specificity,
          "sensitivity": sensitivity,
          "f1-score": f1}
      #
      # End Loop Time
      class_time_end = time.time()
      total_class_time = class_time_end - class_time_start
      print(f"{class_label[i]} Class Run Time: " + str(total_class_time) + "s")
      #
    with open(f'C:\\Users\\nac-calderlab\\Documents\\ECoG_Decoding\\figures\\mean_amplitude_{model_name_fig}_metrics_test.pkl', "wb") as f:
        pickle.dump(metrics_class, f)
    #
    #End Model Timer
    model_end_time = time.time()
    total_model_time = model_end_time - model_start_time
    print(f"{model_name_title} Run Time: " + str(total_model_time) + "s")
#end of model loop

    
    
    
    
    
    
    
    #End Model Loop